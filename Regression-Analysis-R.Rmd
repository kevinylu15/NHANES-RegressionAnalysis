---
title: "NHANES Linear Regression"
author: "Kevin Lu"
date: "2024-11-17"
output:
  pdf_document: default
  rtf_document: true
---

```{r}
knitr::opts_chunk$set(echo = TRUE)
library("sas7bdat")
library("corrplot")
library("gtsummary")
library("dplyr")
library("ggplot2")
library("data.table")
library("car")
library("NHANES")
library("olsrr")
library("tidyr")
library("gridExtra")
```

```{r}
# Load in NHANES dataset
df <- NHANES
```

```{r EDA}
# List of covariates for the model
covariates <- c("SexAge","Gender","HHIncome","Education","PhysActive","SameSex","AlcoholYear","RegularMarij","HardDrugs")
```

Examining relationships between sexual habits and drug use with different variables to determine which models fit better
```{r}
# Model 1: Examining the relationship between smoking status and age at first sexual activity
model <- lm(SexAge ~ SmokeNow, df)
summary(model)

# Model 2: Examining the relationship between age of first alcohol use and age at first sexual activity
model <- lm(SexAge ~ AlcoholYear, df)
summary(model)

# Model 3: Examining the interaction effect of regular marijuana and hard drug use on age at first sexual activity
model <- lm(SexAge ~ RegularMarij + HardDrugs + RegularMarij * HardDrugs, df)
summary(model)

# Display the regression results for Model 3 in a clean table format
model |>
  tbl_regression(intercept = TRUE, show_single_row = c(RegularMarij, HardDrugs)) |>
  as_gt() |> 
  gt::tab_header(title = "SexAge MLR")  

# Model 4: Examining the interaction effect of regular marijuana and hard drug use on the lifetime number of sexual partners
model <- lm(SexNumPartnLife ~ RegularMarij + HardDrugs + RegularMarij * HardDrugs, df)
summary(model)

# Display the regression results for Model 4 
model |>
  tbl_regression(intercept = TRUE, show_single_row = c(RegularMarij, HardDrugs)) |>
  as_gt() |> 
  gt::tab_header(title = "SexNumPartnLife MLR")  # Adding a title to the table

```


```{R New variable}
# Plot histogram of age at first sexual activity
hist(df$SexAge, main = "First Age at which Sexual Activity Occurred")

# Plot histogram of number of sexual partners per year (missing title to be added)
hist(df$SexNumPartYear, main = "Number of Sexual Partners per Year")

# Plot histogram of lifetime number of sexual partners
hist(df$SexNumPartnLife, main = "Lifetime Number of Sexual Partners")

# Show observations where the age at first sexual activity (SexAge) exceeds the current age (Age)
df[which(df$SexAge > df$Age), ]

# Identify observations with more than 40 sexual partners during their lifetime (potential outliers)
boxplot(df$SexNumPartnLife, main = "Number of Sexual Partners Distribution Before Outlier Removal")
df[which(df$SexNumPartnLife > 40), c("Age", "SexAge", "SexNumPartnLife")]

# Remove observations with more than 40 sexual partners
df <- df[-which(df$SexNumPartnLife > 40), ]

# Re-plot the boxplot after removing outliers
boxplot(df$SexNumPartnLife, main = "Number of Sexual Partners Distribution After Outlier Removal")

# Create a new variable: Average sexual frequency (AvgSexFreq) before log transformation
# This variable is calculated as the total lifetime sexual partners divided by years of sexual activity
df <- mutate(df, AvgSexFreq = SexNumPartnLife / (Age - SexAge))
hist(df$AvgSexFreq, main = "AvgSexFreq Before Log Transformation")

# Apply log transformation to AvgSexFreq to reduce skewness and handle extreme values
df <- mutate(df, AvgSexFreq = log(SexNumPartnLife / (Age - SexAge)))
hist(df$AvgSexFreq, main = "AvgSexFreq After Log Transformation")

# Create a summary table grouped by hard drug use
tbl_summary(
  df,
  by = HardDrugs,
  statistic = list(
    all_continuous() ~ "{mean} ({sd})",       # Format for continuous variables
    all_categorical() ~ "{n} / {N} ({p}%)"   # Format for categorical variables
  )
)

```

$$AvgSexFreq = \log\left(\frac{SexNumPartnLife}{Age - SexAge}\right)$$

```{R New variable test}
# Identify observations where AvgSexFreq is negative infinity
# This occurs when the denominator (Age - SexAge) is 0 or the numerator (SexNumPartnLife) is invalid.
obs <- df[is.infinite(df$AvgSexFreq), ]
obs[, c("Age", "SexAge", "SexNumPartnLife")]

# Replace negative infinity in AvgSexFreq with 0 for invalid observations
df$AvgSexFreq[is.infinite(df$AvgSexFreq)] <- 0

# Build a multiple linear regression model to examine factors influencing AvgSexFreq
model <- lm(
  AvgSexFreq ~ SmokeNow + AlcoholYear + RegularMarij + HardDrugs + RegularMarij * HardDrugs + Age + Gender + HHIncome + Education + BMI + DiabetesAge + Depressed + LittleInterest + PhysActive + SameSex,df)
summary(model)

# Generate a clean regression table with specific variables highlighted
model |>
  tbl_regression(
    intercept = TRUE, 
    show_single_row = c(RegularMarij, HardDrugs, Gender, PhysActive, SameSex)
  ) |>
  as_gt() |>
  gt::tab_header(title = "Full model")  # Add a title to the regression table

```

Using the sequential sum of squares we tested for each block of covariates at a significance level 0.001.

```{r Sequential SS}
# Define the sample size
n <- 30

# Perform ANOVA on the linear model to analyze variance components
aov <- anova(
model <- lm(AvgSexFreq ~ SmokeNow + AlcoholYear + RegularMarij + HardDrugs + RegularMarij * HardDrugs + Age + Gender + HHIncome + Education + BMI + DiabetesAge + Depressed + LittleInterest + PhysActive + SameSex, df))

# Calculate the total sum of squares (SSY)
SSY <- sum(aov$"Sum Sq")

# Extract the individual sum of squares (SSQ) for each predictor
SSQ <- aov$"Sum Sq"

# Extract the mean squared error (MSE) from the ANOVA table
MSE <- aov$"Mean Sq"[16]

# Sum of squares for the first group of predictors (SmokeNow, AlcoholYear, RegularMarij, HardDrugs, Interaction)
ss1 <- sum(SSQ[c(1:4, 15)])
print(ss1)

# Calculate the F-statistic and p-value for the first group
fstat1 <- ss1 / 5 / MSE
pval1 <- 1 - pf(q = fstat1, df1 = 5, df2 = n - 16)
print(c(fstat1, pval1))

# Sum of squares for the second group of predictors (Age, Gender, HHIncome, Education)
ss2 <- sum(SSQ[5:8])
print(ss2)

# Calculate the F-statistic and p-value for the second group
fstat2 <- ss2 / 4 / MSE
pval2 <- 1 - pf(q = fstat2, df1 = 4, df2 = n - 16)
print(c(fstat2, pval2))

# Sum of squares for the third group of predictors (BMI, DiabetesAge, Depressed, LittleInterest, PhysActive)
ss3 <- sum(SSQ[9:14])
print(ss3)

# Calculate the F-statistic and p-value for the third group
fstat3 <- ss3 / 5 / MSE
pval3 <- 1 - pf(q = fstat3, df1 = 5, df2 = n - 16)
print(c(fstat3, pval3))

# Sum of squares for the fourth group of predictors (SameSex)
ss4 <- sum(SSQ[14])
print(ss4)

# Calculate the F-statistic and p-value for the fourth group
fstat4 <- ss3 / 1 / MSE
pval4 <- 1 - pf(q = fstat4, df1 = 1, df2 = n - 16)
print(c(fstat4, pval4))
```
(i) $\boldsymbol{\beta}_{substance} = (\beta_{SmokeNow}, \beta_{AlcoholYear},\beta_{RegularMarij}, \beta_{HardDrugs}, \beta_{RegularMarij*HardDrugs})^T$
(ii) $\boldsymbol{\beta}_{Demo} = (\beta_{Age}, \beta_{Gender}, \beta_{HHIncome}, \beta_{Education})^T$
(iii) $\boldsymbol{\beta}_{Health} = (\beta_{BMI},\beta_{DiabetesAges},\beta_{Depressed},\beta_{LittleInterest},\beta_{PhysActive})^T$
(iv) $\boldsymbol{\beta}_{SameSex} = (\beta_{SameSex})^T$


Final model $$AvgSexFreq = X_{Substance}\boldsymbol\beta_{Substance} + X_{Demo}\boldsymbol\beta_{Demo} + \boldsymbol{\epsilon}, \boldsymbol\epsilon \sim N(\boldsymbol{0}, \sigma^2 I)$$

```{r systematic differences of missing values}
# New covariates to consider
new_covariates <- c("AvgSexFreq", "SmokeNow", "AlcoholYear", "RegularMarij", "HardDrugs", 
                "Age", "Gender", "HHIncome", "Education")
# Calculate the number of rows with complete data for the selected covariates
sum(complete.cases(df[, new_covariates]))

# Add a new column 'missingness' to indicate if rows are complete or have missing values
df$missingness <- ifelse(complete.cases(df[, new_covariates]), "Not Missing", "Missing")

# Create a summary table to compare demographic and socioeconomic variables 
# (Age, Gender, HHIncome, Education, MaritalStatus) across missingness groups
tbl_summary(
  df[, c("Age", "Gender", "HHIncome", "Education", "MaritalStatus", "missingness")], 
  by = missingness,
  statistic = list(
    all_continuous() ~ "{mean} ({sd})",        # Mean and standard deviation for continuous variables
    all_categorical() ~ "{n} / {N} ({p}%)"    # Counts and percentages for categorical variables
  )
)

# Fit a logistic regression model to examine predictors of missingness
missingness_comparison <- glm(
  as.factor(missingness) ~ Age + Gender + HHIncome + Education + MaritalStatus, 
  family = binomial, 
  df
)

# Display regression results for missingness predictors in a clean table format
missingness_comparison |>
  tbl_regression(intercept = TRUE) |>         # Include the intercept in the table
  as_gt() |> 
  gt::tab_header(title = "Missingness Comparison")  # Add a title to the regression table

```
Missingness for occurs for those aged below 20 because they are not recorded for some covariates. Why missingness for those aged above 60 occurs is unclear.

```{r missigness graphs}
# Load necessary libraries
library(ggplot2)
library(gridExtra)

# Plot 1: Bar plot of Age with missingness highlighted
p1 <- ggplot(data = df, mapping = aes(x = Age, fill = as.factor(missingness))) +
  geom_bar(stat = "count") +                               # Count the number of occurrences for each Age
  scale_fill_manual(values = c("gray", "red"))             # Use custom colors for missingness categories

# Plot 2: Bar plot of Gender with missingness highlighted
p2 <- ggplot(data = df, mapping = aes(x = Gender, fill = as.factor(missingness))) +
  geom_bar(stat = "count") +                               # Count the number of occurrences for each Gender
  scale_fill_manual(values = c("gray", "red"))             # Use custom colors for missingness categories

# Plot 3: Bar plot of Education with missingness highlighted
p3 <- ggplot(data = df, mapping = aes(x = Education, fill = as.factor(missingness))) +
  geom_bar(stat = "count") +                               # Count the number of occurrences for each Education level
  scale_x_discrete(labels = c("<8th", "9-11th", "HS",      # Custom labels for education levels
                              "Some College", "College Grad")) +
  scale_fill_manual(values = c("gray", "red"))             # Use custom colors for missingness categories

# Plot 4: Bar plot of MaritalStatus with missingness highlighted
p4 <- ggplot(data = df, mapping = aes(x = MaritalStatus, fill = as.factor(missingness))) +
  geom_bar(stat = "count") +                               # Count the number of occurrences for each MaritalStatus
  scale_fill_manual(values = c("gray", "red"))             # Use custom colors for missingness categories

# Plot 5: Bar plot of HHIncome with missingness highlighted
p5 <- ggplot(data = df, mapping = aes(x = HHIncome, fill = as.factor(missingness))) +
  geom_bar(stat = "count") +                               # Count the number of occurrences for each income level
  scale_x_discrete(labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9,  # Custom labels for income levels
                              10, 11, 12, "NA")) +
  scale_fill_manual(values = c("gray", "red"))             # Use custom colors for missingness categories

# Arrange all the plots in a single grid with 5 rows
grid.arrange(p1, p2, p3, p4, p5, nrow = 5)
```



```{r GLH and QQplot}
# Fit an initial multiple linear regression model to predict AvgSexFreq
# The predictors include smoking, alcohol use, marijuana, hard drugs, interaction terms, and demographics
m1 <- lm(AvgSexFreq ~ SmokeNow + AlcoholYear + RegularMarij + HardDrugs + 
           RegularMarij * HardDrugs + Age + Gender + HHIncome + Education, df)

# Display the summary of the initial model
summary(m1)

# Perform General Linear Hypothesis (GLH) test to collapse income categories
# Define a contrast matrix to test specific linear hypotheses about HHIncome categories
Contrast.T <- matrix(c(
  0, 0, 0, 0, 0, 0, 0, 1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
  0, 0, 0, 0, 0, 0, 0, 0, 0, 1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, -1, 0, 0, 0, 0, 0, 0, 0, 0,
  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, -1, 0, 0, 0, 0, 0, 0, 0,
  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, -1, 0, 0, 0, 0, 0, 0,
  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, -1, 0, 0, 0, 0, 0,
  1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0
), byrow = TRUE, nrow = 10)

# Perform linear hypothesis test using the contrast matrix
car::linearHypothesis(model = m1, hypothesis.matrix = Contrast.T)

# Recode HHIncome into a new binary variable segmentincome (Low vs. High)
df <- df |> 
  mutate(segmentincome = ifelse(HHIncome == "5000-9999" | HHIncome == "10000-14999", "Low", "High"))

# Refit the regression model using the new segmentincome variable
m1 <- lm(AvgSexFreq ~ SmokeNow + AlcoholYear + RegularMarij + HardDrugs + 
           RegularMarij * HardDrugs + Age + Gender + segmentincome + Education, df)

# Display the summary of the updated model
summary(m1)

# Create a clean regression table with selected variables highlighted
m1 |>
  tbl_regression(intercept = TRUE, show_single_row = c(SmokeNow, RegularMarij, HardDrugs, Gender, segmentincome)) |>
  as_gt() |> 
  gt::tab_header(title = "AvgSexFreq MLR")  # Add a title to the table

# Extract residuals from the updated model
m1.res <- m1$residuals

# Perform QQ plot to assess normality of residuals
car::qqPlot(m1.res)

```


```{r Residual Plots}
# 1. Added Variable Plots
# Visualize the relationship between each predictor and the response variable,
# adjusted for all other predictors in the model.
car::avPlots(m1)

# 2. Residual Plots
# Assess the residuals for nonlinearity, outliers, or heteroscedasticity.
# type = "response" plots residuals against the response variable.
car::residualPlots(m1, type = "response")

# 3. Durbin-Watson Test
# Check for autocorrelation in residuals (common in time series data).
# A value close to 2 suggests no autocorrelation.
dw_test <- car::durbinWatsonTest(m1)
print(dw_test)

# 4. Variance Inflation Factor (VIF)
# Check for multicollinearity among predictors.
# Fit a non-interaction model to calculate VIF, as interactions can inflate VIF values.
nonintmodel <- lm(AvgSexFreq ~ SmokeNow + AlcoholYear + RegularMarij + Age + 
                    Gender + segmentincome + Education, df)
vif_values <- car::vif(nonintmodel, type = 'predictor')
```

```{r outliers}
# 1. Calculate DFFITS
# DFFITS measures the influence of each observation on the fitted values.
model.deffits <- dffits(m1)

# Identify the observation with the maximum DFFITS value
max_deffits <- model.deffits[which.max(model.deffits)]
cat("Observation with maximum DFFITS:\n")
print(max_deffits)

# 2. Calculate Cook's Distance
# Cook's Distance measures the influence of each observation on the overall model fit.
model.CD <- cooks.distance(m1)

# Identify the observation with the maximum Cook's Distance value
max_CD <- model.CD[which.max(model.CD)]
cat("Observation with maximum Cook's Distance:\n")
print(max_CD)

# 3. Number of Observations and Model Parameters
# n: Number of observations in the dataset
# p: Number of parameters in the model
n <- nrow(df)
p <- m1$rank  # Rank of the model, equivalent to the number of parameters including the intercept

# 4. Plot Cook's Distance
# Create a diagnostic plot for Cook's Distance to visualize influential observations
plot(m1, which = 4)  # Cook's Distance plot (default in base R diagnostic plots)
abline(h = 4 / n, lty = 2)  # Add reference line at 4/n to flag influential observations

# 5. Review Specific Observations
# Extract rows corresponding to potentially influential observations
# (3240, 7919, 8682 are example row indices flagged based on influence diagnostics)
cat("Details of potentially influential observations:\n")
df[c(3240, 7919, 8682), ]
```

t Interpretation is as follows:
$$\frac{f(x+1)}{f(x)}-1 = (e^{\beta_1}-1)*100$$

```{r remove outliers}
# Remove the identified influential observation (row 7919) from the dataset
df2 <- df[-c(7919), ]

# Refit the linear model using the dataset without the influential observation
m2 <- lm(AvgSexFreq ~ SmokeNow + AlcoholYear + RegularMarij + HardDrugs +
           RegularMarij * HardDrugs + Age + Gender + segmentincome + Education, df2)

# Display summaries of both models for comparison
cat("Summary of Model m1 (Original):\n")
summary(m1)

cat("\nSummary of Model m2 (Without Influential Observation):\n")
summary(m2)

# Calculate the percent change in coefficients between the two models
coef_change <- 100 * (abs(coef(m1) - coef(m2))) / coef(m1)
```

```{r rerun qqplot}
# Remove the identified influential observation (row 7919) from the dataset
df2 <- df[-c(7919), ]

# Refit the linear model using the dataset without the influential observation
m2 <- lm(AvgSexFreq ~ SmokeNow + AlcoholYear + RegularMarij + HardDrugs +
           RegularMarij * HardDrugs + Age + Gender + segmentincome + Education, df2)

# Display summaries of both models for comparison
cat("Summary of Model m1 (Original):\n")
summary(m1)

cat("\nSummary of Model m2 (Without Influential Observation):\n")
summary(m2)

# Calculate the percent change in coefficients between the two models
coef_change <- 100 * (abs(coef(m1) - coef(m2))) / coef(m1)
```

